{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from pprint import pprint\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# Defining the environment\n",
        "envr = np.array([[-1, -1, 100],\n",
        "                [-1, -1, -100]])\n",
        "act_names = ['Up', 'Down', 'Right', 'Left']\n",
        "\n",
        "\n",
        "# Seting the hyperparameters\n",
        "al = 0.1  #\"alpha\"\n",
        "gm = 0.9  #\"gamma\"\n",
        "epn = 0.1  #\"epsilon\"\n",
        "noe = 2000\n",
        "\n",
        "# Initialize the Q-table\n",
        "nstates = np.prod(envr.shape)\n",
        "nactions = 4\n",
        "Qtable = np.zeros((nstates, nactions))\n",
        "\n",
        "# Define the helper functions\n",
        "def get_state(rw, cl):\n",
        "    number_cols = envr.shape[1]\n",
        "    return rw * number_cols + cl\n",
        "\n",
        "def get_rw_cl(state):\n",
        "    number_cols = envr.shape[1]\n",
        "    rw = state // number_cols\n",
        "    cl = state % number_cols\n",
        "    return rw, cl\n",
        "\n",
        "def choose_action(state):\n",
        "    if np.random.uniform() < epn:\n",
        "        # Choose a random action\n",
        "        act = np.random.randint(nactions)\n",
        "    else:\n",
        "        # Choose the best action based on the Q-table\n",
        "        act = np.argmax(Qtable[state])\n",
        "    return act\n",
        "\n",
        "# Train the Q-table\n",
        "for epi in range(noe):\n",
        "    # Reset the envrironment for each episode\n",
        "    state = get_state(1, 0)\n",
        "    done = False\n",
        "    \n",
        "    while not done:\n",
        "        # Choose an action\n",
        "        act = choose_action(state)\n",
        "        \n",
        "        # Take the action and observe the next state and reward\n",
        "        rw, cl = get_rw_cl(state)\n",
        "        if act == 0:\n",
        "            rw = max(rw - 1, 0)\n",
        "        elif act == 1:\n",
        "            rw = min(rw + 1, envr.shape[0] - 1)\n",
        "        elif act == 2:\n",
        "            cl = min(cl + 1, envr.shape[1] - 1)\n",
        "        elif act == 3:\n",
        "            cl = max(cl - 1, 0)\n",
        "        next_state = get_state(rw, cl)\n",
        "        reward = envr[rw, cl]\n",
        "        \n",
        "        # Update the Q-table\n",
        "        Qtable[state, act] = (1 - al) * Qtable[state, act] + \\\n",
        "                                 al * (reward + gm * np.max(Qtable[next_state]))\n",
        "        \n",
        "        # Update the state and check if the episode is done\n",
        "        state = next_state\n",
        "        done = (reward == 100) or (reward == -100)\n",
        "print(\"Training of the Artificial Intelligence Agent is Complete.\")    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkla84MbGA_-",
        "outputId": "3f86e8fd-feff-47d6-96e8-b102a792d9a5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training of the Artificial Intelligence Agent is Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def path_policy(init_rw, init_cl, Qtable, envr):\n",
        "    gr, gc = 0, 2  # preset goal to (0, 2)\n",
        "    hr, hc = 1, 2  # preset hole to (1, 2)\n",
        "\n",
        "    path = [(init_rw, init_cl)]\n",
        "\n",
        "    if (init_rw, init_cl) == (gr, gc): \n",
        "        print(\"Error: Given GOAL\")\n",
        "    elif (init_rw, init_cl) == (hr, hc):\n",
        "        print(\"Error: Given HOLE\")\n",
        "    else:\n",
        "        print(\"Best Policy and Shortest Path taken by the Agent from Start Location ({}, {}):\".format(init_rw, init_cl))\n",
        "\n",
        "        while (init_rw, init_cl) != (gr, gc) and (init_rw, init_cl) != (hr, hc):\n",
        "            state = get_state(init_rw, init_cl)\n",
        "            action = np.argmax(Qtable[state])\n",
        "            if action == 0:\n",
        "                init_rw = max(init_rw - 1, 0)\n",
        "            elif action == 1:\n",
        "                init_rw = min(init_rw + 1, envr.shape[0] - 1)\n",
        "            elif action == 2:\n",
        "                init_cl = min(init_cl + 1, envr.shape[1] - 1)\n",
        "            elif action == 3:\n",
        "                init_cl = max(init_cl - 1, 0)\n",
        "            path.append((init_rw, init_cl))\n",
        "\n",
        "        # Print the corresponding actions for each state in the path\n",
        "        print(\"Best Policy :\")\n",
        "        for i in range(len(path)-1):\n",
        "            state = get_state(path[i][0], path[i][1])\n",
        "            act = np.argmax(Qtable[state])\n",
        "            print(\"State {}= {}   Action taken = {}\".format(i+1, path[i], act_names[act]))\n",
        "\n",
        "        # Print the goal or hole at the last state of the path\n",
        "        finalstate = path[-1]\n",
        "        if envr[finalstate[0], finalstate[1]] == 100:\n",
        "            print(\"State {}= GOAL\".format(i+2, path[i]))\n",
        "        else:\n",
        "            print(\"State {}= HOLE\".format(i+2, path[i]))\n",
        "\n",
        "        # Print the path taken to reach the goal\n",
        "        if envr[finalstate[0], finalstate[1]] == 100:\n",
        "            print(\"---------------------\")\n",
        "            print(\"The Quickest Route:\")\n",
        "            for state in path:\n",
        "                if envr[state[0], state[1]] == 100:\n",
        "                    print(\"Goal\")\n",
        "                    break\n",
        "                else:\n",
        "                    print(state,\"-->\")\n",
        "        else:\n",
        "            print(\"No path found to reach the goal.\")\n"
      ],
      "metadata": {
        "id": "-lwPzoaa2VLF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The Q-Table for the given envrironment is:\") \n",
        "print(np.array2string(Qtable).replace('[[',' [').replace(']]',']'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBZgH8Tt2X0e",
        "outputId": "06ba5333-fd06-4d84-c188-d1186cc517ce"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Q-Table for the given envrironment is:\n",
            " [ 18.41856829  18.876419    88.99560428  -0.1       ]\n",
            " [ 88.29920084  78.70981309 100.          78.23317175]\n",
            " [  0.           0.           0.           0.        ]\n",
            " [ 77.85976219  69.89574184  79.1         69.95100688]\n",
            " [ 89.          78.52856987 -99.66186081  69.53973384]\n",
            " [  0.           0.           0.           0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_policy(0, 0, Qtable, envr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbRje68iT140",
        "outputId": "014ed527-edab-46ac-e051-5a656e485526"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Policy and Shortest Path taken by the Agent from Start Location (0, 0):\n",
            "Best Policy :\n",
            "State 1= (0, 0)   Action taken = Right\n",
            "State 2= (0, 1)   Action taken = Right\n",
            "State 3= GOAL\n",
            "---------------------\n",
            "The Quickest Route:\n",
            "(0, 0) -->\n",
            "(0, 1) -->\n",
            "Goal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_policy(1, 0, Qtable, envr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j2rIr-5Zf0l",
        "outputId": "547ccd58-cf51-4869-8e90-042d1df2e32f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Policy and Shortest Path taken by the Agent from Start Location (1, 0):\n",
            "Best Policy :\n",
            "State 1= (1, 0)   Action taken = Right\n",
            "State 2= (1, 1)   Action taken = Up\n",
            "State 3= (0, 1)   Action taken = Right\n",
            "State 4= GOAL\n",
            "---------------------\n",
            "The Quickest Route:\n",
            "(1, 0) -->\n",
            "(1, 1) -->\n",
            "(0, 1) -->\n",
            "Goal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_policy(0, 2, Qtable, envr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXjfIsCWWQcY",
        "outputId": "8365cb3b-20ab-4829-9968-b9eee10dd1fa"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Given GOAL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_policy(1, 2, Qtable, envr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw34a_EVWTco",
        "outputId": "efaaaa3e-8853-4734-8715-03e1e280af87"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Given HOLE\n"
          ]
        }
      ]
    }
  ]
}